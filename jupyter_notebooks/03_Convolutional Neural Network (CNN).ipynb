{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Training the CNN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objectives: Preprocess the cherry leaves dataset for model training.\n",
    "\n",
    "Inputs: Cherry leaves dataset downloaded from Kaggle.\n",
    "\n",
    "Outputs: Preprocessed dataset ready for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps for training the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important Note**: After installing the required packages, you may need to restart the Jupyter Notebook kernel for the changes to take effect. This ensures that the newly installed libraries are properly loaded. You can restart the kernel by selecting \"Kernel\" > \"Restart\" in the Jupyter Notebook menu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Constructing the model CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we are extracting the cherry leaves dataset from a compressed .zip file. This action makes the dataset accessible for further processing. It involves opening the .zip file and extracting its contents into a designated directory, followed by removing the .zip file to clean up our workspace.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/workspaces/Mildew-Detection-in-Cherry-Leaves')\n",
    "print(\"Working directory changed to '/workspaces/Mildew-Detection-in-Cherry-Leaves'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 50, 50  # Adjusted image size\n",
    "batch_size = 20  # Adjusted batch size\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-Defining Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to redefine the parameters if they were not defined in a previous Jupyter Notebook session. Variables defined in one Jupyter Notebook session are not automatically carried over to another session unless explicitly saved and loaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'inputs/mildew_dataset/cherry-leaves/train'\n",
    "validation_dir = 'inputs/mildew_dataset/cherry-leaves/validation'\n",
    "test_dir = 'inputs/mildew_dataset/cherry-leaves/test'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory( train_dir, target_size=(img_width, img_height), batch_size=batch_size, class_mode='binary')\n",
    "validation_generator = validation_datagen.flow_from_directory( validation_dir, target_size=(img_width, img_height), batch_size=batch_size, class_mode='binary')\n",
    "test_generator = test_datagen.flow_from_directory( test_dir, target_size=(img_width, img_height), batch_size=batch_size, class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=15,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.Save the Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After successfully training our CNN, it's crucial to save the model. This enables us to use the model later for making predictions, either in a different environment or as part of an application. We will save the model in the HDF5 format, which is a versatile container format used for storing a model with its architecture, weights, training configuration, and even optimizer state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cherry_leaf_cnn_model.h5')\n",
    "\n",
    "print(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.Cherry Leaf Condition Analysis Using CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we provide a straightforward interface for you to use our Convolutional Neural Network (CNN) model to analyze cherry leaves. Simply upload your images, and the model will classify them as either 'Healthy' or 'Powdery Mildew'. This tool is designed to assist in the rapid assessment of cherry leaf conditions, offering a glimpse into the power of machine learning in agricultural applications.\n",
    "\n",
    "Please upload your cherry leaf images in JPG format, either one by one or as a ZIP file containing multiple images. The model will process each image and present you with its findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 07:08:16.258750: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-12-20 07:08:16.258791: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /workspace/Mildew-Detection-in-Cherry-Leaves/jupyter_notebooks\n",
      "Changed to Directory: /workspace/Mildew-Detection-in-Cherry-Leaves\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 07:08:17.518956: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-12-20 07:08:17.518998: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-12-20 07:08:17.519018: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cefeidas-mildewdetectio-ylblwxu1ny3): /proc/driver/nvidia/version does not exist\n",
      "2023-12-20 07:08:17.519307: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ceb58dced4f4bf4bb3301943a9b94a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='image/jpeg, application/zip', description='Upload', multiple=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a83d9b5639f44efa80954d850c73c02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Analyze Images', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import ipywidgets as widgets\n",
    "from io import BytesIO\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "print(\"Current Working Directory:\", os.getcwd())\n",
    "os.chdir('/workspace/Mildew-Detection-in-Cherry-Leaves')\n",
    "print(\"Changed to Directory:\", os.getcwd())\n",
    "\n",
    "# Load the pre-trained CNN model\n",
    "model = load_model('cherry_leaf_cnn_model.h5')\n",
    "print(\"Model loaded successfully.\")\n",
    "\n",
    "# Function to process and predict an image\n",
    "def process_and_predict_image(uploaded_file):\n",
    "    try:\n",
    "        print(\"Processing image...\")\n",
    "        # Read and process the image\n",
    "        img = Image.open(uploaded_file)\n",
    "        img = img.resize((50, 50))\n",
    "        img_array = image.img_to_array(img) / 255.0\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "        # Predict the condition of the cherry leaf\n",
    "        prediction = model.predict(img_array)\n",
    "        label = 'Healthy' if prediction < 0.5 else 'Powdery Mildew'\n",
    "        display(img)\n",
    "        print(f'Prediction: {label}')\n",
    "    except Exception as e:\n",
    "        print(f'Error processing image: {e}')\n",
    "\n",
    "# File upload widget for images and ZIP files\n",
    "uploader = widgets.FileUpload(accept='image/jpeg, application/zip', multiple=True)\n",
    "display(uploader)\n",
    "\n",
    "# Button to process the uploaded images\n",
    "process_button = widgets.Button(description=\"Analyze Images\")\n",
    "display(process_button)\n",
    "\n",
    "# Function to handle the button click event\n",
    "def on_button_clicked(b):\n",
    "    if not uploader.value:\n",
    "        print(\"No files uploaded.\")\n",
    "        return\n",
    "\n",
    "    print(\"Button clicked. Processing uploaded files...\")\n",
    "    # Process each uploaded file\n",
    "    for name, file_info in uploader.value.items():\n",
    "        print(f\"Processing file: {name}\")\n",
    "        if name.lower().endswith('.zip'):\n",
    "            print(\"Processing ZIP file...\")\n",
    "            # Extract and process images from ZIP file\n",
    "            with zipfile.ZipFile(BytesIO(file_info['content'])) as zfile:\n",
    "                for filename in zfile.namelist():\n",
    "                    print(f\"Extracting and processing image: {filename} from ZIP\")\n",
    "                    with zfile.open(filename) as file:\n",
    "                        process_and_predict_image(file)\n",
    "        else:\n",
    "            print(\"Processing single image...\")\n",
    "            process_and_predict_image(BytesIO(file_info['content']))\n",
    "\n",
    "# Register the click event handler\n",
    "process_button.on_click(on_button_clicked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
